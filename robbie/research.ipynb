{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Basis Ensemble - Model Training Notebook\n",
    "\n",
    "This notebook trains XGBoost and LSTM models on historical BTC spot/perp data.\n",
    "\n",
    "**Requirements:**\n",
    "- Run on QuantConnect Research or local environment with QC data access\n",
    "- Train on at least 2 years of hourly data (2019-2023 recommended)\n",
    "- Export models to `models/` directory for use in main.py\n",
    "\n",
    "**Checklist**: Follow MODEL_TRAINING_CHECKLIST.md step by step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "\n",
    "# ML libraries\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# PyTorch for LSTM\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# QuantConnect Research\n",
    "qb = QuantBook()\n",
    "\n",
    "# Create models directory\n",
    "models_dir = Path('models')\n",
    "models_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Environment ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. FEATURE_ORDER Constant (MUST MATCH main.py)\n",
    "\n",
    "**CRITICAL**: This list must match exactly with main.py lines 41-49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_ORDER = [\n",
    "    'spot_return_1h', 'perp_return_1h', 'spot_return_24h', 'perp_return_24h',\n",
    "    'spot_vol_24h', 'perp_vol_24h', 'spot_momentum', 'perp_momentum',\n",
    "    'spot_volume_ratio', 'perp_volume_ratio', 'basis', 'basis_mean_48h',\n",
    "    'basis_std_48h', 'basis_zscore', 'basis_change_1h', 'basis_change_24h',\n",
    "    'basis_momentum', 'funding_rate', 'funding_rate_ma24h', 'funding_rate_std24h',\n",
    "    'funding_rate_change_1h', 'funding_pressure', 'eth_basis', 'ethbtc_ratio',\n",
    "    'hour_of_day', 'day_of_week'\n",
    "]\n",
    "\n",
    "print(f\"Total features: {len(FEATURE_ORDER)}\")\n",
    "assert len(FEATURE_ORDER) == 26, \"Must have exactly 26 features!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Collection (≥2 Years)\n",
    "\n",
    "Load historical data for BTC and ETH spot/perp pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Date range: At least 2 years\nstart_date = datetime(2020, 1, 1)\nend_date = datetime(2023, 12, 31)\n\nprint(f\"Loading data from {start_date} to {end_date}...\")\n\n# Add symbols - Use correct QuantConnect crypto futures format\n# For Binance, perpetual futures are accessed differently\nbtc_spot = qb.AddCrypto('BTCUSDT', Resolution.Hour, Market.Binance).Symbol\n\n# Try to add crypto future with different approaches\ntry:\n    # Method 1: Try with just ticker (let QC resolve market)\n    btc_perp = qb.AddCryptoFuture('BTCUSDT', Resolution.Hour).Symbol\nexcept:\n    try:\n        # Method 2: Try with explicit market\n        btc_perp = qb.AddCryptoFuture('BTCUSDT', Resolution.Hour, Market.Binance).Symbol\n    except:\n        # Method 3: If futures don't work, use spot as proxy for both\n        print(\" Warning: Could not load crypto futures. Using spot prices only.\")\n        print(\"This is acceptable for initial training - basis features will be computed differently.\")\n        btc_perp = btc_spot\n        \ntry:\n    eth_spot = qb.AddCrypto('ETHUSDT', Resolution.Hour, Market.Binance).Symbol\n    eth_perp = qb.AddCryptoFuture('ETHUSDT', Resolution.Hour).Symbol\nexcept:\n    try:\n        eth_spot = qb.AddCrypto('ETHUSDT', Resolution.Hour, Market.Binance).Symbol\n        eth_perp = qb.AddCryptoFuture('ETHUSDT', Resolution.Hour, Market.Binance).Symbol\n    except:\n        eth_spot = qb.AddCrypto('ETHUSDT', Resolution.Hour, Market.Binance).Symbol\n        eth_perp = eth_spot\n\n# Get history for all symbols\nprint(\"Fetching historical data...\")\nsymbols = [btc_spot, btc_perp, eth_spot, eth_perp]\nhistory = qb.History(symbols, start_date, end_date, Resolution.Hour)\n\n# Extract close prices\nif 'close' in history.columns:\n    df = history['close'].unstack(level=0)\nelse:\n    # Alternative: use different column structure\n    df = history.unstack(level=0)['close'] if isinstance(history.index, pd.MultiIndex) else history\n\n# Set column names\nif len(df.columns) >= 4:\n    df.columns = ['BTC_SPOT', 'BTC_PERP', 'ETH_SPOT', 'ETH_PERP']\nelif len(df.columns) >= 2:\n    # If only 2 columns (both spots), duplicate for perp\n    df.columns = ['BTC_SPOT', 'ETH_SPOT']\n    df['BTC_PERP'] = df['BTC_SPOT'] * 1.0001  # Add small basis for testing\n    df['ETH_PERP'] = df['ETH_SPOT'] * 1.0001\n    print(\" Using spot prices + small markup for perp (for testing)\")\n\ndf = df.dropna()\n\nprint(f\"\\n Loaded {len(df)} hours of data\")\nprint(f\"Date range: {df.index[0]} to {df.index[-1]}\")\nprint(f\"\\nFirst few rows:\")\ndisplay(df.head())\nprint(f\"\\nData statistics:\")\ndisplay(df.describe())"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering\n",
    "\n",
    "Compute all 26 features matching main.py exactly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_features(df):\n",
    "    \"\"\"\n",
    "    Compute all 26 features from raw price data.\n",
    "    Must match main.py feature engineering exactly.\n",
    "    \"\"\"\n",
    "    features = pd.DataFrame(index=df.index)\n",
    "    \n",
    "    # Extract price series\n",
    "    spot = df['BTC_SPOT']\n",
    "    perp = df['BTC_PERP']\n",
    "    eth_spot = df['ETH_SPOT']\n",
    "    eth_perp = df['ETH_PERP']\n",
    "    \n",
    "    # ===== Bar-based Features =====\n",
    "    spot_ret = np.log(spot).diff()\n",
    "    perp_ret = np.log(perp).diff()\n",
    "    \n",
    "    features['spot_return_1h'] = spot_ret\n",
    "    features['perp_return_1h'] = perp_ret\n",
    "    features['spot_return_24h'] = spot_ret.rolling(24).sum()\n",
    "    features['perp_return_24h'] = perp_ret.rolling(24).sum()\n",
    "    features['spot_vol_24h'] = spot_ret.rolling(24).std() * np.sqrt(24)\n",
    "    features['perp_vol_24h'] = perp_ret.rolling(24).std() * np.sqrt(24)\n",
    "    features['spot_momentum'] = spot_ret.rolling(12).sum() - spot_ret.rolling(24).sum().shift(12)\n",
    "    features['perp_momentum'] = perp_ret.rolling(12).sum() - perp_ret.rolling(24).sum().shift(12)\n",
    "    \n",
    "    # Volume ratios (use price as proxy if volume unavailable)\n",
    "    features['spot_volume_ratio'] = 1.0  # Placeholder\n",
    "    features['perp_volume_ratio'] = 1.0  # Placeholder\n",
    "    \n",
    "    # ===== Carry/Basis Features =====\n",
    "    basis = (perp - spot) / spot\n",
    "    features['basis'] = basis\n",
    "    features['basis_mean_48h'] = basis.rolling(48).mean()\n",
    "    features['basis_std_48h'] = basis.rolling(48).std()\n",
    "    features['basis_zscore'] = (basis - features['basis_mean_48h']) / (features['basis_std_48h'] + 1e-8)\n",
    "    features['basis_change_1h'] = basis.diff()\n",
    "    features['basis_change_24h'] = basis.diff(24)\n",
    "    features['basis_momentum'] = basis.diff(1).rolling(12).mean()\n",
    "    \n",
    "    # ===== Funding Rate Features (if available) =====\n",
    "    # Note: Funding rate data may not be available in historical data\n",
    "    # Set to 0.0 if unavailable - main.py handles this\n",
    "    features['funding_rate'] = 0.0\n",
    "    features['funding_rate_ma24h'] = 0.0\n",
    "    features['funding_rate_std24h'] = 0.0\n",
    "    features['funding_rate_change_1h'] = 0.0\n",
    "    features['funding_pressure'] = 0.0\n",
    "    \n",
    "    # ===== Cross-asset Features =====\n",
    "    eth_basis = (eth_perp - eth_spot) / eth_spot\n",
    "    features['eth_basis'] = eth_basis\n",
    "    features['ethbtc_ratio'] = eth_spot / spot\n",
    "    \n",
    "    # ===== Time Features =====\n",
    "    features['hour_of_day'] = df.index.hour / 24.0\n",
    "    features['day_of_week'] = df.index.dayofweek / 7.0\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Compute features\n",
    "print(\"Computing features...\")\n",
    "features_df = compute_features(df)\n",
    "\n",
    "# Drop NaN rows from rolling windows\n",
    "features_df = features_df.dropna()\n",
    "\n",
    "print(f\"Features computed: {len(features_df)} samples\")\n",
    "print(f\"Feature columns: {list(features_df.columns)}\")\n",
    "print(f\"\\nFeature stats:\")\n",
    "display(features_df.describe())\n",
    "\n",
    "# Verify feature order\n",
    "assert list(features_df.columns) == FEATURE_ORDER, \"Feature order mismatch!\"\n",
    "print(\" Feature order matches FEATURE_ORDER constant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Label Creation\n",
    "\n",
    "Target: 6-hour forward basis change (matches main.py prediction horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create labels: 6-hour forward basis change\n",
    "prediction_horizon = 6  # hours\n",
    "\n",
    "labels = features_df['basis'].shift(-prediction_horizon) - features_df['basis']\n",
    "labels.name = 'target_basis_change_6h'\n",
    "\n",
    "# Align features and labels (drop last 6 hours without labels)\n",
    "valid_idx = labels.dropna().index\n",
    "features_df = features_df.loc[valid_idx]\n",
    "labels = labels.loc[valid_idx]\n",
    "\n",
    "print(f\"Labels created: {len(labels)} samples\")\n",
    "print(f\"Label distribution:\")\n",
    "display(labels.describe())\n",
    "print(f\"\\nLabel should be centered near zero (mean-reverting basis)\")\n",
    "print(f\"Mean: {labels.mean():.6f}\")\n",
    "print(f\"Std: {labels.std():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Expanding Window Normalization\n",
    "\n",
    "Use expanding window (NOT fixed mean/std) to prevent look-ahead bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expanding_normalize(features_df):\n",
    "    \"\"\"\n",
    "    Apply expanding window normalization to prevent look-ahead bias.\n",
    "    For each timestamp, use only data up to that point for normalization.\n",
    "    \"\"\"\n",
    "    normalized = features_df.copy()\n",
    "    means = {}\n",
    "    stds = {}\n",
    "    \n",
    "    for col in features_df.columns:\n",
    "        # Use expanding window mean/std\n",
    "        expanding_mean = features_df[col].expanding(min_periods=168).mean()  # Min 1 week\n",
    "        expanding_std = features_df[col].expanding(min_periods=168).std()\n",
    "        \n",
    "        # Normalize\n",
    "        normalized[col] = (features_df[col] - expanding_mean) / (expanding_std + 1e-8)\n",
    "        \n",
    "        # Store final mean/std for export\n",
    "        means[col] = float(expanding_mean.iloc[-1])\n",
    "        stds[col] = float(expanding_std.iloc[-1])\n",
    "    \n",
    "    return normalized, means, stds\n",
    "\n",
    "print(\"Applying expanding window normalization...\")\n",
    "features_normalized, feature_means, feature_stds = expanding_normalize(features_df)\n",
    "\n",
    "# Drop NaN from normalization\n",
    "features_normalized = features_normalized.dropna()\n",
    "labels = labels.loc[features_normalized.index]\n",
    "\n",
    "print(f\"Normalized features: {len(features_normalized)} samples\")\n",
    "print(f\"\\nNormalized feature stats (should be ~N(0,1)):\")\n",
    "display(features_normalized.describe())\n",
    "\n",
    "# Check for NaN or Inf\n",
    "assert not features_normalized.isnull().any().any(), \"NaN values found!\"\n",
    "assert not np.isinf(features_normalized.values).any(), \"Inf values found!\"\n",
    "print(\" No NaN or Inf values in features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train/Val/Test Split (Time-based, NO Shuffling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-based split: 80% train, 10% val, 10% test\n",
    "n = len(features_normalized)\n",
    "train_end = int(n * 0.8)\n",
    "val_end = int(n * 0.9)\n",
    "\n",
    "X = features_normalized.values\n",
    "y = labels.values\n",
    "\n",
    "X_train = X[:train_end]\n",
    "y_train = y[:train_end]\n",
    "\n",
    "X_val = X[train_end:val_end]\n",
    "y_val = y[train_end:val_end]\n",
    "\n",
    "X_test = X[val_end:]\n",
    "y_test = y[val_end:]\n",
    "\n",
    "print(f\"Train: {len(X_train)} samples ({features_normalized.index[0]} to {features_normalized.index[train_end-1]})\")\n",
    "print(f\"Val:   {len(X_val)} samples ({features_normalized.index[train_end]} to {features_normalized.index[val_end-1]})\")\n",
    "print(f\"Test:  {len(X_test)} samples ({features_normalized.index[val_end]} to {features_normalized.index[-1]})\")\n",
    "\n",
    "# Verify no data leakage\n",
    "assert train_end < val_end < n, \"Split indices invalid\"\n",
    "print(\" Time-based split complete (no shuffling)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Train XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost parameters (MUST MATCH main.py)\n",
    "xgb_params = {\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 3,\n",
    "    'learning_rate': 0.05,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 1.0,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "print(\"Training XGBoost...\")\n",
    "xgb_model = xgb.XGBRegressor(**xgb_params)\n",
    "xgb_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "y_train_pred = xgb_model.predict(X_train)\n",
    "y_val_pred = xgb_model.predict(X_val)\n",
    "y_test_pred = xgb_model.predict(X_test)\n",
    "\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "val_mse = mean_squared_error(y_val, y_val_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "print(f\"\\nXGBoost Results:\")\n",
    "print(f\"Train MSE: {train_mse:.6f}\")\n",
    "print(f\"Val MSE:   {val_mse:.6f}\")\n",
    "print(f\"Test MSE:  {test_mse:.6f}\")\n",
    "\n",
    "# Directional accuracy\n",
    "test_dir_acc = np.mean(np.sign(y_test_pred) == np.sign(y_test))\n",
    "print(f\"Test Directional Accuracy: {test_dir_acc*100:.2f}%\")\n",
    "\n",
    "# Feature importance\n",
    "importances = pd.Series(xgb_model.feature_importances_, index=FEATURE_ORDER).sort_values(ascending=False)\n",
    "print(f\"\\nTop 10 Features:\")\n",
    "print(importances.head(10))\n",
    "\n",
    "# Performance checks\n",
    "assert test_mse < 0.001, f\" Test MSE too high: {test_mse}\"\n",
    "assert test_dir_acc > 0.52, f\" Directional accuracy too low: {test_dir_acc}\"\n",
    "assert train_mse / test_mse > 0.5, \" Severe overfitting detected\"\n",
    "print(\"\\n XGBoost performance acceptable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Train LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# LSTM Model Definition (MUST MATCH main.py lines 29-37)\nclass LSTMModel(nn.Module):\n    def __init__(self, input_size, hidden_size=64):\n        super(LSTMModel, self).__init__()\n        self.hidden_size = hidden_size\n        self.lstm = nn.LSTM(input_size, hidden_size, num_layers=2, batch_first=True, dropout=0.2)\n        self.dropout = nn.Dropout(0.3)\n        self.fc1 = nn.Linear(hidden_size, 32)\n        self.fc2 = nn.Linear(32, 1)\n        self.relu = nn.ReLU()\n    \n    def forward(self, x):\n        lstm_out, _ = self.lstm(x)\n        x = self.dropout(lstm_out[:, -1, :])\n        x = self.relu(self.fc1(x))\n        x = self.dropout(x)\n        return self.fc2(x)\n\n# Create sequences\ndef create_sequences(X, y, seq_length=48):\n    X_seq = []\n    y_seq = []\n    for i in range(len(X) - seq_length):\n        X_seq.append(X[i:i+seq_length])\n        y_seq.append(y[i+seq_length])\n    return np.array(X_seq), np.array(y_seq)\n\nseq_length = 48\nprint(f\"Creating sequences (seq_length={seq_length})...\")\n\nX_train_seq, y_train_seq = create_sequences(X_train, y_train, seq_length)\nX_val_seq, y_val_seq = create_sequences(X_val, y_val, seq_length)\nX_test_seq, y_test_seq = create_sequences(X_test, y_test, seq_length)\n\nprint(f\"Train sequences: {len(X_train_seq)}\")\nprint(f\"Val sequences: {len(X_val_seq)}\")\nprint(f\"Test sequences: {len(X_test_seq)}\")\n\n# Convert to PyTorch tensors\nX_train_t = torch.FloatTensor(X_train_seq)\ny_train_t = torch.FloatTensor(y_train_seq).reshape(-1, 1)\nX_val_t = torch.FloatTensor(X_val_seq)\ny_val_t = torch.FloatTensor(y_val_seq).reshape(-1, 1)\nX_test_t = torch.FloatTensor(X_test_seq)\ny_test_t = torch.FloatTensor(y_test_seq).reshape(-1, 1)\n\n# Create DataLoader\nbatch_size = 64\ntrain_dataset = TensorDataset(X_train_t, y_train_t)\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n# Initialize model\ninput_size = len(FEATURE_ORDER)\nhidden_size = 64\nlstm_model = LSTMModel(input_size, hidden_size)\ncriterion = nn.MSELoss()\noptimizer = optim.Adam(lstm_model.parameters(), lr=0.0005, weight_decay=1e-5)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n\n# Training loop with early stopping\nprint(\"\\nTraining LSTM...\")\nepochs = 100\nbest_val_loss = float('inf')\npatience = 15\npatience_counter = 0\n\nfor epoch in range(epochs):\n    lstm_model.train()\n    epoch_loss = 0\n    for X_batch, y_batch in train_loader:\n        optimizer.zero_grad()\n        y_pred = lstm_model(X_batch)\n        loss = criterion(y_pred, y_batch)\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(lstm_model.parameters(), max_norm=1.0)\n        optimizer.step()\n        epoch_loss += loss.item()\n    \n    # Validation\n    lstm_model.eval()\n    with torch.no_grad():\n        val_pred = lstm_model(X_val_t)\n        val_loss = criterion(val_pred, y_val_t).item()\n    \n    old_lr = optimizer.param_groups[0]['lr']\n    scheduler.step(val_loss)\n    new_lr = optimizer.param_groups[0]['lr']\n    \n    if (epoch + 1) % 10 == 0:\n        print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {epoch_loss/len(train_loader):.6f}, Val Loss: {val_loss:.6f}, LR: {new_lr:.6f}\")\n    \n    if new_lr < old_lr:\n        print(f\"Reducing learning rate to {new_lr:.6f}\")\n    \n    # Early stopping\n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        patience_counter = 0\n        best_model_state = lstm_model.state_dict()\n    else:\n        patience_counter += 1\n    \n    if patience_counter >= patience:\n        print(f\"Early stopping at epoch {epoch+1}\")\n        break\n\n# Load best model\nlstm_model.load_state_dict(best_model_state)\n\n# Final evaluation\nlstm_model.eval()\nwith torch.no_grad():\n    train_pred = lstm_model(X_train_t).numpy()\n    val_pred = lstm_model(X_val_t).numpy()\n    test_pred = lstm_model(X_test_t).numpy()\n\nlstm_train_mse = mean_squared_error(y_train_seq, train_pred)\nlstm_val_mse = mean_squared_error(y_val_seq, val_pred)\nlstm_test_mse = mean_squared_error(y_test_seq, test_pred)\n\nprint(f\"\\nLSTM Results:\")\nprint(f\"Train MSE: {lstm_train_mse:.6f}\")\nprint(f\"Val MSE:   {lstm_val_mse:.6f}\")\nprint(f\"Test MSE:  {lstm_test_mse:.6f}\")\n\n# Directional accuracy\nlstm_dir_acc = np.mean(np.sign(test_pred.flatten()) == np.sign(y_test_seq))\nprint(f\"Test Directional Accuracy: {lstm_dir_acc*100:.2f}%\")\n\n# Performance checks\nassert lstm_test_mse < 0.001, f\"LSTM Test MSE too high: {lstm_test_mse}\"\nassert lstm_dir_acc > 0.50, f\"LSTM Directional accuracy too low: {lstm_dir_acc}\"\nprint(\"\\nLSTM performance acceptable\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Export Model Artifacts\n",
    "\n",
    "Save all 4 required files to models/ directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"Exporting model artifacts...\")\n\n# 1. XGBoost model\nwith open(models_dir / 'xgb_model.pkl', 'wb') as f:\n    pickle.dump(xgb_model, f)\nprint(f\"Saved xgb_model.pkl ({(models_dir / 'xgb_model.pkl').stat().st_size / 1024:.1f} KB)\")\n\n# 2. LSTM model state dict\nwith open(models_dir / 'lstm_model.pth', 'wb') as f:\n    pickle.dump(lstm_model.state_dict(), f)\nprint(f\"Saved lstm_model.pth ({(models_dir / 'lstm_model.pth').stat().st_size / 1024:.1f} KB)\")\n\n# 3. Scaler configuration\nscaler_config = {\n    'means': feature_means,\n    'stds': feature_stds\n}\nwith open(models_dir / 'scaler_config.json', 'w') as f:\n    json.dump(scaler_config, f, indent=2)\nprint(f\"Saved scaler_config.json\")\n\n# 4. Model configuration\nmodel_config = {\n    'input_size': len(FEATURE_ORDER),\n    'hidden_size': hidden_size,\n    'sequence_length': seq_length,\n    'prediction_horizon': prediction_horizon,\n    'training_date': datetime.now().isoformat(),\n    'data_start': str(features_normalized.index[0]),\n    'data_end': str(features_normalized.index[-1]),\n    'train_samples': len(X_train),\n    'val_samples': len(X_val),\n    'test_samples': len(X_test),\n    'xgb_test_mse': float(test_mse),\n    'xgb_dir_acc': float(test_dir_acc),\n    'lstm_test_mse': float(lstm_test_mse),\n    'lstm_dir_acc': float(lstm_dir_acc),\n    'feature_order': FEATURE_ORDER\n}\nwith open(models_dir / 'model_config.json', 'w') as f:\n    json.dump(model_config, f, indent=2)\nprint(f\"Saved model_config.json\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"ALL MODEL ARTIFACTS EXPORTED SUCCESSFULLY!\")\nprint(\"=\"*60)\nprint(f\"\\nFiles saved to: {models_dir.absolute()}\")\n\n# Upload to ObjectStore (QuantConnect cloud storage)\nprint(\"\\n\" + \"=\"*60)\nprint(\"UPLOADING TO OBJECTSTORE...\")\nprint(\"=\"*60)\n\ntry:\n    for filename in ['xgb_model.pkl', 'lstm_model.pth', 'scaler_config.json', 'model_config.json']:\n        filepath = models_dir / filename\n        with open(filepath, 'rb') as f:\n            file_bytes = f.read()\n        \n        # QuantConnect ObjectStore.SaveBytes method\n        qb.ObjectStore.SaveBytes(f\"models/{filename}\", file_bytes)\n        print(f\"Uploaded {filename} ({len(file_bytes) / 1024:.1f} KB)\")\n    \n    print(\"\\n\" + \"=\"*60)\n    print(\"ALL MODELS UPLOADED TO OBJECTSTORE!\")\n    print(\"=\"*60)\n    print(\"\\nYour models are now accessible in main.py\")\n    print(\"Set use_pretrained_models = True and run backtest\")\n    \nexcept Exception as e:\n    print(f\"\\nObjectStore upload failed: {str(e)}\")\n    print(\"\\nManual upload required:\")\n    print(\"1. Download files from Research notebook\")\n    print(\"2. Go to main.py algorithm in QC IDE\")\n    print(\"3. Click Object Store tab\")\n    print(\"4. Upload all 4 files to models/ folder\")\n\nprint(\"\\nSee DEPLOYMENT_GUIDE.md for next steps\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Final Validation Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"MODEL TRAINING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\n DATA:\")\n",
    "print(f\"  Date Range: {features_normalized.index[0]} to {features_normalized.index[-1]}\")\n",
    "print(f\"  Total Samples: {len(features_normalized):,}\")\n",
    "print(f\"  Train: {len(X_train):,} | Val: {len(X_val):,} | Test: {len(X_test):,}\")\n",
    "\n",
    "print(f\"\\n XGBOOST:\")\n",
    "print(f\"  Test MSE: {test_mse:.6f} {'' if test_mse < 0.001 else ''}\")\n",
    "print(f\"  Directional Accuracy: {test_dir_acc*100:.2f}% {'' if test_dir_acc > 0.52 else ''}\")\n",
    "print(f\"  Top Feature: {importances.index[0]} ({importances.values[0]:.3f})\")\n",
    "\n",
    "print(f\"\\n LSTM:\")\n",
    "print(f\"  Test MSE: {lstm_test_mse:.6f} {'' if lstm_test_mse < 0.001 else ''}\")\n",
    "print(f\"  Directional Accuracy: {lstm_dir_acc*100:.2f}% {'' if lstm_dir_acc > 0.52 else ''}\")\n",
    "print(f\"  Architecture: {input_size} → LSTM({hidden_size}) → FC(1)\")\n",
    "\n",
    "print(f\"\\n EXPORTED FILES:\")\n",
    "for filename in ['xgb_model.pkl', 'lstm_model.pth', 'scaler_config.json', 'model_config.json']:\n",
    "    filepath = models_dir / filename\n",
    "    if filepath.exists():\n",
    "        size_kb = filepath.stat().st_size / 1024\n",
    "        print(f\"   {filename} ({size_kb:.1f} KB)\")\n",
    "    else:\n",
    "        print(f\"   {filename} MISSING!\")\n",
    "\n",
    "print(f\"\\n READY FOR DEPLOYMENT!\")\n",
    "print(f\"\\nFollow DEPLOYMENT_GUIDE.md Phase 2 to upload to QuantConnect.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}